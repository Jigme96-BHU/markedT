{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardCardData = pd.read_csv('./card.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>-1.359807134</th>\n",
       "      <th>-0.072781173</th>\n",
       "      <th>2.536346738</th>\n",
       "      <th>1.378155224</th>\n",
       "      <th>-0.33832077</th>\n",
       "      <th>0.462387778</th>\n",
       "      <th>0.239598554</th>\n",
       "      <th>0.098697901</th>\n",
       "      <th>0.36378697</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.018306778</th>\n",
       "      <th>0.277837576</th>\n",
       "      <th>-0.11047391</th>\n",
       "      <th>0.066928075</th>\n",
       "      <th>0.128539358</th>\n",
       "      <th>-0.189114844</th>\n",
       "      <th>0.133558377</th>\n",
       "      <th>-0.021053053</th>\n",
       "      <th>149.62</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  -1.359807134  -0.072781173  2.536346738  1.378155224  -0.33832077  \\\n",
       "0  0.0      1.191857      0.266151     0.166480     0.448154     0.060018   \n",
       "1  1.0     -1.358354     -1.340163     1.773209     0.379780    -0.503198   \n",
       "2  1.0     -0.966272     -0.185226     1.792993    -0.863291    -0.010309   \n",
       "3  2.0     -1.158233      0.877737     1.548718     0.403034    -0.407193   \n",
       "4  2.0     -0.425966      0.960523     1.141109    -0.168252     0.420987   \n",
       "\n",
       "   0.462387778  0.239598554  0.098697901  0.36378697  ...  -0.018306778  \\\n",
       "0    -0.082361    -0.078803     0.085102   -0.255425  ...     -0.225775   \n",
       "1     1.800499     0.791461     0.247676   -1.514654  ...      0.247998   \n",
       "2     1.247203     0.237609     0.377436   -1.387024  ...     -0.108300   \n",
       "3     0.095921     0.592941    -0.270533    0.817739  ...     -0.009431   \n",
       "4    -0.029728     0.476201     0.260314   -0.568671  ...     -0.208254   \n",
       "\n",
       "   0.277837576  -0.11047391  0.066928075  0.128539358  -0.189114844  \\\n",
       "0    -0.638672     0.101288    -0.339846     0.167170      0.125895   \n",
       "1     0.771679     0.909412    -0.689281    -0.327642     -0.139097   \n",
       "2     0.005274    -0.190321    -1.175575     0.647376     -0.221929   \n",
       "3     0.798278    -0.137458     0.141267    -0.206010      0.502292   \n",
       "4    -0.559825    -0.026398    -0.371427    -0.232794      0.105915   \n",
       "\n",
       "   0.133558377  -0.021053053  149.62  0.1  \n",
       "0    -0.008983      0.014724    2.69    0  \n",
       "1    -0.055353     -0.059752  378.66    0  \n",
       "2     0.062723      0.061458  123.50    0  \n",
       "3     0.219422      0.215153   69.99    0  \n",
       "4     0.253844      0.081080    3.67    0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardCardData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '-1.359807134', '-0.072781173', '2.536346738', '1.378155224',\n",
       "       '-0.33832077', '0.462387778', '0.239598554', '0.098697901',\n",
       "       '0.36378697', '0.090794172', '-0.551599533', '-0.617800856',\n",
       "       '-0.991389847', '-0.311169354', '1.468176972', '-0.470400525',\n",
       "       '0.207971242', '0.02579058', '0.40399296', '0.251412098',\n",
       "       '-0.018306778', '0.277837576', '-0.11047391', '0.066928075',\n",
       "       '0.128539358', '-0.189114844', '0.133558377', '-0.021053053', '149.62',\n",
       "       '0.1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardCardData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'V{i}' for i in range(0, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardCardData.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardCardData.rename(columns={'V0': 'Time', 'V29': 'amount','V30':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'amount',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardCardData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>amount</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284806 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "1            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "2            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "3            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "4            2.0  -0.425966   0.960523  1.141109 -0.168252  0.420987   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284801  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284802  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284803  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284804  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284805  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "1       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "2       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "3       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "4      -0.029728  0.476201  0.260314 -0.568671  ... -0.208254 -0.559825   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284801 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284802  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284803  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284804  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284805 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  amount  \\\n",
       "0       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "1       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "2      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "3      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "4      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284801  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284802  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284803 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284804 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284805  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        target  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "284801       0  \n",
       "284802       0  \n",
       "284803       0  \n",
       "284804       0  \n",
       "284805       0  \n",
       "\n",
       "[284806 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardCardData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cardCardData.drop(columns= \"target\", axis = 1)\n",
    "y = cardCardData.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data\n",
    "#70% for train, 20% test, 10% val\n",
    "x_train_validate, x_test, y_train_validate, y_test = train_test_split(X,y, test_size=0.2,random_state=33)\n",
    "x_train, x_val,y_train,y_val = train_test_split(x_train_validate,y_train_validate,test_size=(1/8),random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.09135113\n",
      "Iteration 2, loss = 0.08259245\n",
      "Iteration 3, loss = 0.07313112\n",
      "Iteration 4, loss = 0.06923026\n",
      "Iteration 5, loss = 0.06616509\n",
      "Iteration 6, loss = 0.06047728\n",
      "Iteration 7, loss = 0.05760743\n",
      "Iteration 8, loss = 0.02702281\n",
      "Iteration 9, loss = 0.01521952\n",
      "Iteration 10, loss = 0.01417531\n",
      "Iteration 11, loss = 0.01391895\n",
      "Iteration 12, loss = 0.01474565\n",
      "Iteration 13, loss = 0.01427547\n",
      "Iteration 14, loss = 0.01409289\n",
      "Iteration 15, loss = 0.01400439\n",
      "Iteration 16, loss = 0.01452451\n",
      "Iteration 17, loss = 0.01450097\n",
      "Iteration 18, loss = 0.01484945\n",
      "Iteration 19, loss = 0.01385048\n",
      "Iteration 20, loss = 0.01480716\n",
      "Iteration 21, loss = 0.01369339\n",
      "Iteration 22, loss = 0.01428433\n",
      "Iteration 23, loss = 0.01428843\n",
      "Iteration 24, loss = 0.01468217\n",
      "Iteration 25, loss = 0.01431194\n",
      "Iteration 26, loss = 0.01427925\n",
      "Iteration 27, loss = 0.01348581\n",
      "Iteration 28, loss = 0.01434190\n",
      "Iteration 29, loss = 0.01451808\n",
      "Iteration 30, loss = 0.01396027\n",
      "Iteration 31, loss = 0.01469015\n",
      "Iteration 32, loss = 0.01419994\n",
      "Iteration 33, loss = 0.01442150\n",
      "Iteration 34, loss = 0.01480645\n",
      "Iteration 35, loss = 0.01440056\n",
      "Iteration 36, loss = 0.01429980\n",
      "Iteration 37, loss = 0.01456926\n",
      "Iteration 38, loss = 0.01453134\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10219597\n",
      "Iteration 2, loss = 0.09947042\n",
      "Iteration 3, loss = 0.09022288\n",
      "Iteration 4, loss = 0.08107907\n",
      "Iteration 5, loss = 0.07595071\n",
      "Iteration 6, loss = 0.06414118\n",
      "Iteration 7, loss = 0.05573124\n",
      "Iteration 8, loss = 0.02486620\n",
      "Iteration 9, loss = 0.01500358\n",
      "Iteration 10, loss = 0.01936969\n",
      "Iteration 11, loss = 0.01758391\n",
      "Iteration 12, loss = 0.01536914\n",
      "Iteration 13, loss = 0.01535343\n",
      "Iteration 14, loss = 0.01650915\n",
      "Iteration 15, loss = 0.01545841\n",
      "Iteration 16, loss = 0.01732247\n",
      "Iteration 17, loss = 0.01566456\n",
      "Iteration 18, loss = 0.01517428\n",
      "Iteration 19, loss = 0.01514686\n",
      "Iteration 20, loss = 0.01536882\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10616502\n",
      "Iteration 2, loss = 0.09487385\n",
      "Iteration 3, loss = 0.07514902\n",
      "Iteration 4, loss = 0.04009406\n",
      "Iteration 5, loss = 0.01689390\n",
      "Iteration 6, loss = 0.01976551\n",
      "Iteration 7, loss = 0.02038551\n",
      "Iteration 8, loss = 0.01908554\n",
      "Iteration 9, loss = 0.01864635\n",
      "Iteration 10, loss = 0.02007742\n",
      "Iteration 11, loss = 0.02049952\n",
      "Iteration 12, loss = 0.01926468\n",
      "Iteration 13, loss = 0.01823377\n",
      "Iteration 14, loss = 0.02016190\n",
      "Iteration 15, loss = 0.01785440\n",
      "Iteration 16, loss = 0.01889023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08485863\n",
      "Iteration 2, loss = 0.08095764\n",
      "Iteration 3, loss = 0.07993027\n",
      "Iteration 4, loss = 0.07221874\n",
      "Iteration 5, loss = 0.06798137\n",
      "Iteration 6, loss = 0.06173485\n",
      "Iteration 7, loss = 0.06483358\n",
      "Iteration 8, loss = 0.05796425\n",
      "Iteration 9, loss = 0.05891219\n",
      "Iteration 10, loss = 0.05745269\n",
      "Iteration 11, loss = 0.05619213\n",
      "Iteration 12, loss = 0.05401690\n",
      "Iteration 13, loss = 0.05218969\n",
      "Iteration 14, loss = 0.05005150\n",
      "Iteration 15, loss = 0.05068759\n",
      "Iteration 16, loss = 0.04351991\n",
      "Iteration 17, loss = 0.05655078\n",
      "Iteration 18, loss = 0.04881232\n",
      "Iteration 19, loss = 0.03722568\n",
      "Iteration 20, loss = 0.02359666\n",
      "Iteration 21, loss = 0.01478935\n",
      "Iteration 22, loss = 0.01483059\n",
      "Iteration 23, loss = 0.01407935\n",
      "Iteration 24, loss = 0.01375830\n",
      "Iteration 25, loss = 0.01415173\n",
      "Iteration 26, loss = 0.01362428\n",
      "Iteration 27, loss = 0.01412094\n",
      "Iteration 28, loss = 0.01392289\n",
      "Iteration 29, loss = 0.01356969\n",
      "Iteration 30, loss = 0.01360879\n",
      "Iteration 31, loss = 0.01314906\n",
      "Iteration 32, loss = 0.01362472\n",
      "Iteration 33, loss = 0.01333761\n",
      "Iteration 34, loss = 0.01329672\n",
      "Iteration 35, loss = 0.01323622\n",
      "Iteration 36, loss = 0.01324527\n",
      "Iteration 37, loss = 0.01371973\n",
      "Iteration 38, loss = 0.01328383\n",
      "Iteration 39, loss = 0.01309376\n",
      "Iteration 40, loss = 0.01323741\n",
      "Iteration 41, loss = 0.01345534\n",
      "Iteration 42, loss = 0.01341545\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10381444\n",
      "Iteration 2, loss = 0.08948142\n",
      "Iteration 3, loss = 0.09340615\n",
      "Iteration 4, loss = 0.08733501\n",
      "Iteration 5, loss = 0.07956485\n",
      "Iteration 6, loss = 0.07765866\n",
      "Iteration 7, loss = 0.07526203\n",
      "Iteration 8, loss = 0.06802272\n",
      "Iteration 9, loss = 0.06217116\n",
      "Iteration 10, loss = 0.06403853\n",
      "Iteration 11, loss = 0.05004182\n",
      "Iteration 12, loss = 0.05279733\n",
      "Iteration 13, loss = 0.04110490\n",
      "Iteration 14, loss = 0.02742411\n",
      "Iteration 15, loss = 0.01755299\n",
      "Iteration 16, loss = 0.01400333\n",
      "Iteration 17, loss = 0.01407521\n",
      "Iteration 18, loss = 0.01400502\n",
      "Iteration 19, loss = 0.01390218\n",
      "Iteration 20, loss = 0.01622371\n",
      "Iteration 21, loss = 0.01355789\n",
      "Iteration 22, loss = 0.01458247\n",
      "Iteration 23, loss = 0.01423651\n",
      "Iteration 24, loss = 0.01404201\n",
      "Iteration 25, loss = 0.01404243\n",
      "Iteration 26, loss = 0.01367200\n",
      "Iteration 27, loss = 0.01605970\n",
      "Iteration 28, loss = 0.01402728\n",
      "Iteration 29, loss = 0.01487756\n",
      "Iteration 30, loss = 0.01434609\n",
      "Iteration 31, loss = 0.01395498\n",
      "Iteration 32, loss = 0.01541886\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10577357\n",
      "Iteration 2, loss = 0.09464029\n",
      "Iteration 3, loss = 0.09589063\n",
      "Iteration 4, loss = 0.07952588\n",
      "Iteration 5, loss = 0.07447812\n",
      "Iteration 6, loss = 0.08098071\n",
      "Iteration 7, loss = 0.07138953\n",
      "Iteration 8, loss = 0.06075320\n",
      "Iteration 9, loss = 0.06320578\n",
      "Iteration 10, loss = 0.06152168\n",
      "Iteration 11, loss = 0.03010827\n",
      "Iteration 12, loss = 0.01894835\n",
      "Iteration 13, loss = 0.01766089\n",
      "Iteration 14, loss = 0.01426146\n",
      "Iteration 15, loss = 0.01512523\n",
      "Iteration 16, loss = 0.01448489\n",
      "Iteration 17, loss = 0.01654446\n",
      "Iteration 18, loss = 0.01504472\n",
      "Iteration 19, loss = 0.01402644\n",
      "Iteration 20, loss = 0.01574359\n",
      "Iteration 21, loss = 0.01472177\n",
      "Iteration 22, loss = 0.01631950\n",
      "Iteration 23, loss = 0.01575055\n",
      "Iteration 24, loss = 0.01444055\n",
      "Iteration 25, loss = 0.01502131\n",
      "Iteration 26, loss = 0.01428855\n",
      "Iteration 27, loss = 0.01514286\n",
      "Iteration 28, loss = 0.01405177\n",
      "Iteration 29, loss = 0.01495342\n",
      "Iteration 30, loss = 0.01444547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08368163\n",
      "Iteration 2, loss = 0.06755914\n",
      "Iteration 3, loss = 0.06306995\n",
      "Iteration 4, loss = 0.05794166\n",
      "Iteration 5, loss = 0.07130220\n",
      "Iteration 6, loss = 0.06965237\n",
      "Iteration 7, loss = 0.05819158\n",
      "Iteration 8, loss = 0.05574006\n",
      "Iteration 9, loss = 0.05796624\n",
      "Iteration 10, loss = 0.06017279\n",
      "Iteration 11, loss = 0.05439352\n",
      "Iteration 12, loss = 0.05476409\n",
      "Iteration 13, loss = 0.05402135\n",
      "Iteration 14, loss = 0.05245605\n",
      "Iteration 15, loss = 0.05272103\n",
      "Iteration 16, loss = 0.05554134\n",
      "Iteration 17, loss = 0.05433437\n",
      "Iteration 18, loss = 0.05544065\n",
      "Iteration 19, loss = 0.04248974\n",
      "Iteration 20, loss = 0.04606609\n",
      "Iteration 21, loss = 0.04967026\n",
      "Iteration 22, loss = 0.04989109\n",
      "Iteration 23, loss = 0.04416213\n",
      "Iteration 24, loss = 0.04833832\n",
      "Iteration 25, loss = 0.04640986\n",
      "Iteration 26, loss = 0.06404333\n",
      "Iteration 27, loss = 0.05923710\n",
      "Iteration 28, loss = 0.05642076\n",
      "Iteration 29, loss = 0.05226429\n",
      "Iteration 30, loss = 0.04689179\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08900105\n",
      "Iteration 2, loss = 0.08936753\n",
      "Iteration 3, loss = 0.07314198\n",
      "Iteration 4, loss = 0.07625666\n",
      "Iteration 5, loss = 0.06590157\n",
      "Iteration 6, loss = 0.07791872\n",
      "Iteration 7, loss = 0.07300120\n",
      "Iteration 8, loss = 0.07014014\n",
      "Iteration 9, loss = 0.06962213\n",
      "Iteration 10, loss = 0.07414639\n",
      "Iteration 11, loss = 0.06796801\n",
      "Iteration 12, loss = 0.05862223\n",
      "Iteration 13, loss = 0.06273762\n",
      "Iteration 14, loss = 0.05573646\n",
      "Iteration 15, loss = 0.05489725\n",
      "Iteration 16, loss = 0.06204902\n",
      "Iteration 17, loss = 0.05732776\n",
      "Iteration 18, loss = 0.05077267\n",
      "Iteration 19, loss = 0.06414677\n",
      "Iteration 20, loss = 0.05100452\n",
      "Iteration 21, loss = 0.04694901\n",
      "Iteration 22, loss = 0.05281465\n",
      "Iteration 23, loss = 0.06183774\n",
      "Iteration 24, loss = 0.05375336\n",
      "Iteration 25, loss = 0.05692443\n",
      "Iteration 26, loss = 0.04724875\n",
      "Iteration 27, loss = 0.05855915\n",
      "Iteration 28, loss = 0.04797671\n",
      "Iteration 29, loss = 0.05769572\n",
      "Iteration 30, loss = 0.04759010\n",
      "Iteration 31, loss = 0.06345823\n",
      "Iteration 32, loss = 0.06909262\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10470983\n",
      "Iteration 2, loss = 0.09657112\n",
      "Iteration 3, loss = 0.09062578\n",
      "Iteration 4, loss = 0.08304369\n",
      "Iteration 5, loss = 0.09437035\n",
      "Iteration 6, loss = 0.07795650\n",
      "Iteration 7, loss = 0.08259097\n",
      "Iteration 8, loss = 0.09034704\n",
      "Iteration 9, loss = 0.09907407\n",
      "Iteration 10, loss = 0.08527223\n",
      "Iteration 11, loss = 0.09492155\n",
      "Iteration 12, loss = 0.08869399\n",
      "Iteration 13, loss = 0.07467638\n",
      "Iteration 14, loss = 0.07141355\n",
      "Iteration 15, loss = 0.09009091\n",
      "Iteration 16, loss = 0.08294189\n",
      "Iteration 17, loss = 0.09351928\n",
      "Iteration 18, loss = 0.08062488\n",
      "Iteration 19, loss = 0.08077850\n",
      "Iteration 20, loss = 0.07587118\n",
      "Iteration 21, loss = 0.07501389\n",
      "Iteration 22, loss = 0.08728746\n",
      "Iteration 23, loss = 0.07265571\n",
      "Iteration 24, loss = 0.08298478\n",
      "Iteration 25, loss = 0.07690813\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01946745\n",
      "Iteration 2, loss = 0.01374665\n",
      "Iteration 3, loss = 0.01292145\n",
      "Iteration 4, loss = 0.01292459\n",
      "Iteration 5, loss = 0.01293084\n",
      "Iteration 6, loss = 0.01291123\n",
      "Iteration 7, loss = 0.01293421\n",
      "Iteration 8, loss = 0.01293615\n",
      "Iteration 9, loss = 0.01293450\n",
      "Iteration 10, loss = 0.01293128\n",
      "Iteration 11, loss = 0.01291976\n",
      "Iteration 12, loss = 0.01293503\n",
      "Iteration 13, loss = 0.01292662\n",
      "Iteration 14, loss = 0.01292630\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.03180189\n",
      "Iteration 2, loss = 0.01686662\n",
      "Iteration 3, loss = 0.01360221\n",
      "Iteration 4, loss = 0.01293371\n",
      "Iteration 5, loss = 0.01292839\n",
      "Iteration 6, loss = 0.01293720\n",
      "Iteration 7, loss = 0.01293401\n",
      "Iteration 8, loss = 0.01292351\n",
      "Iteration 9, loss = 0.01292292\n",
      "Iteration 10, loss = 0.01293361\n",
      "Iteration 11, loss = 0.01292866\n",
      "Iteration 12, loss = 0.01293209\n",
      "Iteration 13, loss = 0.01292757\n",
      "Iteration 14, loss = 0.01293250\n",
      "Iteration 15, loss = 0.01292798\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.05443349\n",
      "Iteration 2, loss = 0.02532301\n",
      "Iteration 3, loss = 0.01683486\n",
      "Iteration 4, loss = 0.02241161\n",
      "Iteration 5, loss = 0.01481658\n",
      "Iteration 6, loss = 0.01564312\n",
      "Iteration 7, loss = 0.01505938\n",
      "Iteration 8, loss = 0.01585197\n",
      "Iteration 9, loss = 0.01361864\n",
      "Iteration 10, loss = 0.01705320\n",
      "Iteration 11, loss = 0.01336892\n",
      "Iteration 12, loss = 0.01345056\n",
      "Iteration 13, loss = 0.01453665\n",
      "Iteration 14, loss = 0.01485340\n",
      "Iteration 15, loss = 0.01583274\n",
      "Iteration 16, loss = 0.01346492\n",
      "Iteration 17, loss = 0.01512101\n",
      "Iteration 18, loss = 0.01482606\n",
      "Iteration 19, loss = 0.01311746\n",
      "Iteration 20, loss = 0.01328428\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [10, 20, 50]\n",
    "hidden_layers = [(10,), (50,), (100,)]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for hl in hidden_layers:\n",
    "            mlp_classifier = MLPClassifier(verbose=True,\n",
    "                            hidden_layer_sizes=hl,\n",
    "                            activation='relu',\n",
    "                            batch_size=bs,\n",
    "                            solver='adam',\n",
    "                            learning_rate_init=lr,\n",
    "                            random_state=42).fit(x_train,y_train)\n",
    "            \n",
    "            trainig_score = mlp_classifier.score(x_train,y_train)\n",
    "            test_score = mlp_classifier.score(x_test, y_test)\n",
    "\n",
    "            # Store the results\n",
    "            results.append({\n",
    "                'learning_rate': lr,\n",
    "                'batch_size': bs,\n",
    "                'hidden_layers': hl,\n",
    "                'train_score': trainig_score,\n",
    "                'test_score': test_score\n",
    "            })\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998259</td>\n",
       "      <td>0.998385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998059</td>\n",
       "      <td>0.998280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>0.998666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.100</td>\n",
       "      <td>50</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.100</td>\n",
       "      <td>50</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100</td>\n",
       "      <td>50</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.998367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  batch_size hidden_layers  train_score  test_score\n",
       "0           0.001          10         (10,)     0.998244    0.998367\n",
       "1           0.001          10         (50,)     0.998244    0.998367\n",
       "2           0.001          10        (100,)     0.998244    0.998367\n",
       "3           0.001          20         (10,)     0.998244    0.998367\n",
       "4           0.001          20         (50,)     0.998259    0.998385\n",
       "5           0.001          20        (100,)     0.998244    0.998367\n",
       "6           0.001          50         (10,)     0.998059    0.998280\n",
       "7           0.001          50         (50,)     0.998535    0.998666\n",
       "8           0.001          50        (100,)     0.998275    0.998385\n",
       "9           0.010          10         (10,)     0.998244    0.998367\n",
       "10          0.010          10         (50,)     0.998244    0.998367\n",
       "11          0.010          10        (100,)     0.998244    0.998350\n",
       "12          0.010          20         (10,)     0.998244    0.998367\n",
       "13          0.010          20         (50,)     0.998244    0.998367\n",
       "14          0.010          20        (100,)     0.998244    0.998367\n",
       "15          0.010          50         (10,)     0.998244    0.998367\n",
       "16          0.010          50         (50,)     0.998244    0.998367\n",
       "17          0.010          50        (100,)     0.998244    0.998367\n",
       "18          0.100          10         (10,)     0.998244    0.998367\n",
       "19          0.100          10         (50,)     0.998244    0.998367\n",
       "20          0.100          10        (100,)     0.998244    0.998367\n",
       "21          0.100          20         (10,)     0.998244    0.998367\n",
       "22          0.100          20         (50,)     0.998244    0.998367\n",
       "23          0.100          20        (100,)     0.998244    0.998367\n",
       "24          0.100          50         (10,)     0.998244    0.998367\n",
       "25          0.100          50         (50,)     0.998244    0.998367\n",
       "26          0.100          50        (100,)     0.998244    0.998367"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sem3",
   "language": "python",
   "name": "sem3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

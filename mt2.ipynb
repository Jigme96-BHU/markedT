{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = pd.read_csv('./abalone.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
       "       'Viscera weight', 'Shell weight', 'Rings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole weight      0\n",
       "Shucked weight    0\n",
       "Viscera weight    0\n",
       "Shell weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3l/z6qgybl11yv5bhm29b0_g45c0000gn/T/ipykernel_1673/396968222.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabalone\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabalone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mabalone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/Sem3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4302\u001b[0m         elif (\n\u001b[1;32m   4303\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/Sem3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4425\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4426\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4427\u001b[0m             \u001b[0mlen_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen_cols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4429\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4431\u001b[0m             \u001b[0;31m# align right-hand-side columns if self.columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m             \u001b[0;31m# is multi-index and self[key] is a sub-frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "abalone['Sex']=pd.get_dummies(abalone, columns=['Sex'])\n",
    "abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abalone.drop(columns= \"Rings\", axis = 1)\n",
    "y = abalone.iloc[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0       2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera weight  Shell weight  \n",
       "0             0.1010        0.1500  \n",
       "1             0.0485        0.0700  \n",
       "2             0.1415        0.2100  \n",
       "3             0.1140        0.1550  \n",
       "4             0.0395        0.0550  \n",
       "...              ...           ...  \n",
       "4172          0.2390        0.2490  \n",
       "4173          0.2145        0.2605  \n",
       "4174          0.2875        0.3080  \n",
       "4175          0.2610        0.2960  \n",
       "4176          0.3765        0.4950  \n",
       "\n",
       "[4177 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rings\n",
       "0        15\n",
       "1         7\n",
       "2         9\n",
       "3        10\n",
       "4         7\n",
       "...     ...\n",
       "4172     11\n",
       "4173     10\n",
       "4174      9\n",
       "4175     10\n",
       "4176     12\n",
       "\n",
       "[4177 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data\n",
    "#70% for train, 20% test, 10% val\n",
    "x_train_validate, x_test, y_train_validate, y_test = train_test_split(X,y, test_size=0.2,random_state=33)\n",
    "x_train, x_val,y_train,y_val = train_test_split(x_train_validate,y_train_validate,test_size=(1/8),random_state=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data standardisation \n",
    "\n",
    "# to have standard range for all the feature(mean = 0 and SD= 1)\n",
    "# of we dont do standardisatioin, if a feature has a variance that is much larger than other feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigmelhaden/miniforge3/envs/Sem3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 55.28018718\n",
      "Iteration 2, loss = 48.49018281\n",
      "Iteration 3, loss = 42.42923447\n",
      "Iteration 4, loss = 36.82563194\n",
      "Iteration 5, loss = 31.64306831\n",
      "Iteration 6, loss = 27.01874585\n",
      "Iteration 7, loss = 23.20704895\n",
      "Iteration 8, loss = 20.33481064\n",
      "Iteration 9, loss = 18.38354043\n",
      "Iteration 10, loss = 17.11073269\n",
      "Iteration 11, loss = 16.13923221\n",
      "Iteration 12, loss = 15.29047273\n",
      "Iteration 13, loss = 14.41741659\n",
      "Iteration 14, loss = 13.50448909\n",
      "Iteration 15, loss = 12.55229206\n",
      "Iteration 16, loss = 11.56924552\n",
      "Iteration 17, loss = 10.57883801\n",
      "Iteration 18, loss = 9.60317022\n",
      "Iteration 19, loss = 8.65757174\n",
      "Iteration 20, loss = 7.76259203\n",
      "Iteration 21, loss = 6.92542935\n",
      "Iteration 22, loss = 6.16808862\n",
      "Iteration 23, loss = 5.50992333\n",
      "Iteration 24, loss = 4.95521657\n",
      "Iteration 25, loss = 4.50065022\n",
      "Iteration 26, loss = 4.13564326\n",
      "Iteration 27, loss = 3.84883197\n",
      "Iteration 28, loss = 3.62878282\n",
      "Iteration 29, loss = 3.45817250\n",
      "Iteration 30, loss = 3.33644561\n",
      "Iteration 31, loss = 3.23234796\n",
      "Iteration 32, loss = 3.15971633\n",
      "Iteration 33, loss = 3.09459175\n",
      "Iteration 34, loss = 3.04362556\n",
      "Iteration 35, loss = 2.99601998\n",
      "Iteration 36, loss = 2.95869915\n",
      "Iteration 37, loss = 2.92274505\n",
      "Iteration 38, loss = 2.89202633\n",
      "Iteration 39, loss = 2.86045130\n",
      "Iteration 40, loss = 2.83275457\n",
      "Iteration 41, loss = 2.80608118\n",
      "Iteration 42, loss = 2.78253689\n",
      "Iteration 43, loss = 2.75718648\n",
      "Iteration 44, loss = 2.73554677\n",
      "Iteration 45, loss = 2.71752516\n",
      "Iteration 46, loss = 2.69638288\n",
      "Iteration 47, loss = 2.67715989\n",
      "Iteration 48, loss = 2.65847794\n",
      "Iteration 49, loss = 2.64280031\n",
      "Iteration 50, loss = 2.62372958\n",
      "Iteration 51, loss = 2.60828787\n",
      "Iteration 52, loss = 2.59395242\n",
      "Iteration 53, loss = 2.57848272\n",
      "Iteration 54, loss = 2.56300897\n",
      "Iteration 55, loss = 2.55003064\n",
      "Iteration 56, loss = 2.53688716\n",
      "Iteration 57, loss = 2.52239062\n",
      "Iteration 58, loss = 2.51172874\n",
      "Iteration 59, loss = 2.50158661\n",
      "Iteration 60, loss = 2.49017976\n",
      "Iteration 61, loss = 2.47671142\n",
      "Iteration 62, loss = 2.46578330\n",
      "Iteration 63, loss = 2.45772099\n",
      "Iteration 64, loss = 2.44742132\n",
      "Iteration 65, loss = 2.43730040\n",
      "Iteration 66, loss = 2.42600212\n",
      "Iteration 67, loss = 2.42048579\n",
      "Iteration 68, loss = 2.41136008\n",
      "Iteration 69, loss = 2.40220150\n",
      "Iteration 70, loss = 2.39293343\n",
      "Iteration 71, loss = 2.38431866\n",
      "Iteration 72, loss = 2.37752392\n",
      "Iteration 73, loss = 2.36980175\n",
      "Iteration 74, loss = 2.36368412\n",
      "Iteration 75, loss = 2.36133607\n",
      "Iteration 76, loss = 2.35136089\n",
      "Iteration 77, loss = 2.34390463\n",
      "Iteration 78, loss = 2.33698019\n",
      "Iteration 79, loss = 2.33065733\n",
      "Iteration 80, loss = 2.32562810\n",
      "Iteration 81, loss = 2.31798115\n",
      "Iteration 82, loss = 2.31350490\n",
      "Iteration 83, loss = 2.31156624\n",
      "Iteration 84, loss = 2.30495648\n",
      "Iteration 85, loss = 2.29775995\n",
      "Iteration 86, loss = 2.29221883\n",
      "Iteration 87, loss = 2.28692942\n",
      "Iteration 88, loss = 2.28301176\n",
      "Iteration 89, loss = 2.27863708\n",
      "Iteration 90, loss = 2.27787884\n",
      "Iteration 91, loss = 2.26605393\n",
      "Iteration 92, loss = 2.26895587\n",
      "Iteration 93, loss = 2.26405550\n",
      "Iteration 94, loss = 2.25682544\n",
      "Iteration 95, loss = 2.25342590\n",
      "Iteration 96, loss = 2.24886840\n",
      "Iteration 97, loss = 2.24509587\n",
      "Iteration 98, loss = 2.24235582\n",
      "Iteration 99, loss = 2.23824514\n",
      "Iteration 100, loss = 2.23691977\n",
      "Iteration 101, loss = 2.23131646\n",
      "Iteration 102, loss = 2.22945793\n",
      "Iteration 103, loss = 2.22435478\n",
      "Iteration 104, loss = 2.22067173\n",
      "Iteration 105, loss = 2.22266007\n",
      "Iteration 106, loss = 2.21999196\n",
      "Iteration 107, loss = 2.21311609\n",
      "Iteration 108, loss = 2.21083468\n",
      "Iteration 109, loss = 2.20663383\n",
      "Iteration 110, loss = 2.20504788\n",
      "Iteration 111, loss = 2.20134122\n",
      "Iteration 112, loss = 2.20176741\n",
      "Iteration 113, loss = 2.19932183\n",
      "Iteration 114, loss = 2.19558040\n",
      "Iteration 115, loss = 2.19147064\n",
      "Iteration 116, loss = 2.19221291\n",
      "Iteration 117, loss = 2.18567399\n",
      "Iteration 118, loss = 2.18859491\n",
      "Iteration 119, loss = 2.18205525\n",
      "Iteration 120, loss = 2.17862139\n",
      "Iteration 121, loss = 2.17689053\n",
      "Iteration 122, loss = 2.17505030\n",
      "Iteration 123, loss = 2.17387859\n",
      "Iteration 124, loss = 2.17931146\n",
      "Iteration 125, loss = 2.17440391\n",
      "Iteration 126, loss = 2.16651216\n",
      "Iteration 127, loss = 2.16591727\n",
      "Iteration 128, loss = 2.16225707\n",
      "Iteration 129, loss = 2.16485357\n",
      "Iteration 130, loss = 2.15912575\n",
      "Iteration 131, loss = 2.16012480\n",
      "Iteration 132, loss = 2.15854455\n",
      "Iteration 133, loss = 2.15795562\n",
      "Iteration 134, loss = 2.15180917\n",
      "Iteration 135, loss = 2.15307355\n",
      "Iteration 136, loss = 2.15059524\n",
      "Iteration 137, loss = 2.14625816\n",
      "Iteration 138, loss = 2.14546592\n",
      "Iteration 139, loss = 2.14317934\n",
      "Iteration 140, loss = 2.14200372\n",
      "Iteration 141, loss = 2.14073484\n",
      "Iteration 142, loss = 2.13738950\n",
      "Iteration 143, loss = 2.13817279\n",
      "Iteration 144, loss = 2.13929811\n",
      "Iteration 145, loss = 2.13633253\n",
      "Iteration 146, loss = 2.13264596\n",
      "Iteration 147, loss = 2.13337279\n",
      "Iteration 148, loss = 2.13295901\n",
      "Iteration 149, loss = 2.12921918\n",
      "Iteration 150, loss = 2.12842384\n",
      "Iteration 151, loss = 2.13038527\n",
      "Iteration 152, loss = 2.13238608\n",
      "Iteration 153, loss = 2.12298687\n",
      "Iteration 154, loss = 2.12381328\n",
      "Iteration 155, loss = 2.11993173\n",
      "Iteration 156, loss = 2.11821963\n",
      "Iteration 157, loss = 2.11909023\n",
      "Iteration 158, loss = 2.11498829\n",
      "Iteration 159, loss = 2.11871540\n",
      "Iteration 160, loss = 2.11556898\n",
      "Iteration 161, loss = 2.11488741\n",
      "Iteration 162, loss = 2.11720170\n",
      "Iteration 163, loss = 2.11364634\n",
      "Iteration 164, loss = 2.11029541\n",
      "Iteration 165, loss = 2.10789940\n",
      "Iteration 166, loss = 2.10801102\n",
      "Iteration 167, loss = 2.10849176\n",
      "Iteration 168, loss = 2.10463187\n",
      "Iteration 169, loss = 2.10338281\n",
      "Iteration 170, loss = 2.10796910\n",
      "Iteration 171, loss = 2.10765362\n",
      "Iteration 172, loss = 2.10241083\n",
      "Iteration 173, loss = 2.09894675\n",
      "Iteration 174, loss = 2.09853981\n",
      "Iteration 175, loss = 2.09706236\n",
      "Iteration 176, loss = 2.09707105\n",
      "Iteration 177, loss = 2.09460326\n",
      "Iteration 178, loss = 2.09748305\n",
      "Iteration 179, loss = 2.09718110\n",
      "Iteration 180, loss = 2.09504433\n",
      "Iteration 181, loss = 2.09402982\n",
      "Iteration 182, loss = 2.08956795\n",
      "Iteration 183, loss = 2.08798335\n",
      "Iteration 184, loss = 2.08780584\n",
      "Iteration 185, loss = 2.08802128\n",
      "Iteration 186, loss = 2.09109729\n",
      "Iteration 187, loss = 2.08520137\n",
      "Iteration 188, loss = 2.08652614\n",
      "Iteration 189, loss = 2.08758597\n",
      "Iteration 190, loss = 2.08172574\n",
      "Iteration 191, loss = 2.08049552\n",
      "Iteration 192, loss = 2.08191058\n",
      "Iteration 193, loss = 2.07957802\n",
      "Iteration 194, loss = 2.08114648\n",
      "Iteration 195, loss = 2.09039008\n",
      "Iteration 196, loss = 2.07858952\n",
      "Iteration 197, loss = 2.07856623\n",
      "Iteration 198, loss = 2.07836741\n",
      "Iteration 199, loss = 2.07447435\n",
      "Iteration 200, loss = 2.07485610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigmelhaden/miniforge3/envs/Sem3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Feed forward neural network \n",
    "#we use a neural network to learn the relationship between the target and the feature\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(verbose=True).fit(x_train_scaler,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': True,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_regressor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score of MLP: 0.5945820797592261\n",
      "Validation score of MLP: 0.5075222168953791\n",
      "accuracy on unseen  of MLP: 0.5580206719834271\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score of MLP:\", mlp_regressor.score(x_train_scaler,y_train))\n",
    "\n",
    "# also standardise test data\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "print(\"Validation score of MLP:\", mlp_regressor.score(x_val_scaled, y_val))\n",
    "\n",
    "# also standardise test data\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "print(\"accuracy on unseen  of MLP:\", mlp_regressor.score(x_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Predict on the training data\n",
    "y_train_pred = mlp_regressor.predict(x_train_scaler)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = mlp_regressor.predict(x_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE of MLP: 4.144581127165962\n",
      "Test MSE of MLP: 5.154472864182014\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MSE of MLP:\", mse)\n",
    "print(\"Test MSE of MLP:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00034223, -0.04636339, -0.05044793, -0.04803442, -0.03515527,\n",
       "        -0.01532917, -0.04917071, -0.04366378],\n",
       "       [-0.04636339,  1.00034223,  0.98796197,  0.8068839 ,  0.92689769,\n",
       "         0.89891732,  0.9038784 ,  0.8958424 ],\n",
       "       [-0.05044793,  0.98796197,  1.00034223,  0.81171166,  0.92657357,\n",
       "         0.89399832,  0.89943199,  0.90270037],\n",
       "       [-0.04803442,  0.8068839 ,  0.81171166,  1.00034223,  0.79652525,\n",
       "         0.75252625,  0.77388217,  0.79115401],\n",
       "       [-0.03515527,  0.92689769,  0.92657357,  0.79652525,  1.00034223,\n",
       "         0.96824937,  0.96443879,  0.95411169],\n",
       "       [-0.01532917,  0.89891732,  0.89399832,  0.75252625,  0.96824937,\n",
       "         1.00034223,  0.92777475,  0.87898874],\n",
       "       [-0.04917071,  0.9038784 ,  0.89943199,  0.77388217,  0.96443879,\n",
       "         0.92777475,  1.00034223,  0.90209386],\n",
       "       [-0.04366378,  0.8958424 ,  0.90270037,  0.79115401,  0.95411169,\n",
       "         0.87898874,  0.90209386,  1.00034223]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "covariance_matrix = np.cov(x_train_scaler.T)\n",
    "covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues:\n",
      " [6.31650935 0.9993403  0.31095222 0.16747684 0.12024776 0.06935446\n",
      " 0.01196089 0.00689603] \n",
      "\n",
      "eigenvectors:\n",
      " [[-2.04249856e-02  9.99040389e-01 -2.52549567e-02 -1.34178327e-02\n",
      "  -1.28465387e-02 -2.26026573e-02 -2.61611182e-03 -7.16208469e-04]\n",
      " [ 3.84765912e-01  2.07360915e-03  2.75737927e-03 -5.89714128e-01\n",
      "   8.87505942e-02 -3.96436097e-02  7.02440353e-01 -3.61912191e-02]\n",
      " [ 3.84867901e-01 -2.27840417e-03 -1.82899553e-02 -5.91510683e-01\n",
      "   1.24026651e-02 -2.97494949e-03 -7.07576329e-01  2.87255901e-02]\n",
      " [ 3.41701625e-01 -1.02326863e-02 -8.97850436e-01  2.44605324e-01\n",
      "   1.28809219e-01  2.28426719e-02  6.88866777e-03  2.65800631e-03]\n",
      " [ 3.91828591e-01  1.77220410e-02  2.10119242e-01  2.50244424e-01\n",
      "  -4.75347812e-02  1.04231513e-01 -3.73948641e-02 -8.51388147e-01]\n",
      " [ 3.78904652e-01  3.82214763e-02  3.01624473e-01  2.62661409e-01\n",
      "   4.94397635e-01  5.61411778e-01 -1.57175995e-04  3.67953549e-01]\n",
      " [ 3.81988029e-01  1.55900318e-03  2.28325702e-01  2.88229438e-01\n",
      "   1.70368492e-01 -8.03189223e-01 -2.41913054e-02  2.10119753e-01]\n",
      " [ 3.79000628e-01  5.16918279e-03  7.49974077e-02  1.66286079e-01\n",
      "  -8.36360363e-01  1.61946122e-01  6.22524855e-02  3.05705015e-01]]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "print('eigenvalues:\\n',eigenvalues,'\\n\\neigenvectors:\\n',eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.789, 0.125, 0.039, 0.021, 0.015, 0.009, 0.001, 0.001]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "explained_variance = [round((i/np.sum(eigenvalues)), 3) for i in sorted(eigenvalues, reverse=True)]\n",
    "print(explained_variance)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x_axis_labels = ['pc' + str(i) for i in np.arange(8)]\n",
    "ax.bar(x_axis_labels,explained_variance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
       "       'Viscera weight', 'Shell weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sem3",
   "language": "python",
   "name": "sem3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
